---
title: deeplearning笔记-chapter9-卷积网络
date: 2018-05-29 11:04:21
tags: deeplearning笔记
---

# 卷积网络

## 动机（为什么）

原理：
自然信号具有层次化结构的属性，更高层次的属性时通过低层次属性组合获得的。如在图形中，边缘的局部属性组合图案，图案组合成目标。文本，语音都存在类似的层次结构。
<!-- more -->
卷积网络的特点是能够捕获到输入数据的局部特征，然后通过多层结构将低层次特征组合成高层次特征。
核心的思想是：**局部连接，权值共享，池化操作，多层结构**
1. 局部连接
局部连接也叫做稀疏连接，全连接网络中的输出单元会和每一个输入单元进行交互，带来的问题是参数的爆炸。CNN通过控制卷积核大小远小于输入大小，减少了大量参数。

2. 权值共享
CNN模型中，某一层的卷积核组会对所有的输入数据进行处理，在处理过程中，卷积核参数是不变的。目的也是为了减少参数量。

3. 池化操作
池化操作是将相邻位置语义相似的特征组合成一个特征，带来了输入表示的不变性。
另外，也可以减少下一层的数据量，降低计算量。

4. 多层连接
多层连接是为了能够使得将下层提取到的低层次特征组合成高层次特征，特征层次越高，更容易使用简单分类器完成分类任务的特征。
但是带来的问题有过拟合，梯度消失等问题。目前也有相应的解决方法。过拟合：dropout，BN，正则化等，梯度消失：BN，ReLU，残差连接结构等。

## 池化
https://www.zhihu.com/question/23437871/answer/24696910

pooling的结果是使得特征减少，参数减少，但pooling的目的并不仅在于此。pooling目的是为了保持某种不变性（旋转、平移、伸缩等），常用的有mean-pooling，max-pooling和Stochastic-pooling三种。
mean-pooling，即对邻域内特征点只求平均，max-pooling，即对邻域内特征点取最大。根据相关理论，特征提取的误差主要来自两个方面：（1）邻域大小受限造成的估计值方差增大；（2）卷积层参数误差造成估计均值的偏移。一般来说，mean-pooling能减小第一种误差，更多的保留图像的背景信息，max-pooling能减小第二种误差，更多的保留纹理信息。Stochastic-pooling则介于两者之间，通过对像素点按照数值大小赋予概率，再按照概率进行亚采样，在平均意义上，与mean-pooling近似，在局部意义上，则服从max-pooling的准则。


## 深度CNN

### 为什么要深？
自然信号中具有层次化结构的特点，CNN模型中高层能够将低层次的特征组合成高层次特征。高层次的特征能够使用简单的分类器就完成分类任务。
所以，模型越深，提取到的特征层次越高，分类的效果就会越好。但是，也会带来过拟合的风险。

### 为什么可以做到深度？
1. 数据量多
2. GPU强大的并行计算能力
3. ReLU，BN，Dropout，残差连接等trick方法。


