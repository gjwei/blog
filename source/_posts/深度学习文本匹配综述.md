---
title: 深度学习文本匹配综述
date: 2018-05-04 20:19:42
tags: 
- deep learning
- NLP
---
## 介绍
最近想参加下蚂蚁金服的语义相似度匹配的比赛，看下一篇综述性质的文章，了解下深度学习是如何应用到这个领域的。
http://cjc.ict.ac.cn/online/onlinepaper/pl-201745181647.pdf
<!-- more -->

## 论文内容
文本匹配面临的问题：
1. 词语匹配的多元性
如”苹果“这个词，既可以当做水果，也可以是一个公司的名称

2. 短语匹配的结构性
多个词语可以按照一定的结构组合成短语，匹配两个短语需要考虑短语的结构信息。
3. 层次性

### 深度模型的引入
深度学习的方法，可以自动从原始数据中抽取特征，免去了大量的人工设计特征的开销。首先特征提取的过程是模型的一部分，根据数据的不同，可以很方便的适配到各种文本匹配的任务中。
现在的深度模型加上词向量的技术，可以更好的解决词语匹配的多元性问题。

### 深度模型介绍
1. 基于单语义文档表示的深度学习模型
2. 多语义文档表示的深度模型
3. 直接建模匹配模式的深度学习模型

单语义模型的做法是将单个文本表示成一个**稠密向量（分布式表达）**，然后计算两个向量之间的相似度作为文本的匹配度。

多语义模型认为单一粒度的向量表示一段文本不够精细，需要多语义表示，也就是分别提取**词，短语，句子**等不同级别的表达向量，再计算不同粒度向量之间的相似度作为

直接建模的方法是更早的让两个文本进行交互，然后挖掘出交互后的模式特征，总和得到相似度。
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fqzlb0z7uzj30h508qmxe.jpg)

文本匹配可以用在搜索引擎中，两者分别是查询项和文档；在问答系统中，两者分别是答案和问题。

### 问题简介
抽象成数学的概念，两个训练数据的集合$S_{train}={(s_1^{(i)}, s_2^{(2)},r^{(i)})}$
s表示文本，r表示对象之间的相似程度。

### 传统的方法
主要是基于人工提取特征，问题的焦点是如何设置合适的文本匹配学习算法学习到最优的匹配模型。
人工提取特征的缺点：
1. 代价大，花费很多的时间精力做特征工程
2. 基于主题模型的隐空间模型比较粗糙，不能精确建模文本匹配中的语义相似程度
3. 传统方法很难发觉到一些隐含在大量数据中的含义不明确的特征


## 深度模型的方法
深度学习用在NLP的优势：
1. 深度模型可以将单词表示为语义空间中的向量，利用向量之间的距离可以更准确描述两个单词之间的语义相关性
2. 模型自身是具有层次化和序列化的，能够自然的描述自然语言中的层次结构，序列结构和组合操作
3. 可以很好地利用到大数据的优势和高性能计算的能力。

### 单语义文档表示
将文档表示成一个向量的方法，通过表达的相似度凉衡量两个对象的匹配程度。
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fqznjp6tfgj30gj0a63yl.jpg)

#### 使用CNN来表示文档
深度语义结构网络（Convolution Deep Semantic)。
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fqznlac0vtj30hz0g1aaj.jpg)
使用卷积网络，提取到sequence的分布式表达，然后将两个句子的向量拼接到一起，输入到一个全连接层中。

### 基于RNN的模型

CNN无法捕捉到长距离依赖关系的问题。
将两个s使用RNN表示成一个向量，然后计算两个向量表示之间的**余弦距离**作为相似度的度量，最终输出匹配值。


## 多语义文档表示的模型方法
不仅考虑两个文本最终表示向量的相似程度，也会生成局部短语或者更长短语的表示进行匹配。
多粒度的匹配可以更好地弥补单语义表示方法在压缩整个句子过程中的信息损失，从而达到更好的效果。

### 多粒度CNN（MultiGranCNN模型）
将一个句子拆解成四种层次，单词级别，短语级别和长短句级别，句子级别。
之后将两个句子不同级别的特征进行两两相似度匹配，得到一个相似度的矩阵，进行动态最大值池化得到两个句子的相似度得分。
模型的架构如下：
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fqzo0eacpyj30hi0aoq3r.jpg)

### 多角度RNN
RNN在扫描一个句子过程中，能够冲不同位置输出一个表示，这个表示是开始到当前位置的内容整合。
Wan等人发现了多视角RNN网络（MV-LSTM)

![](https://ws3.sinaimg.cn/large/006tKfTcgy1fqzo3l8om5j30hi0c0aad.jpg)
使用双向的LSTM编码信息，然后两个句子中每个hidden state进行求解相似度计算，得到一个相似度矩阵，通过最大池化的方法得到一个向量，然后输入到分类器中。

## 小结下单语义和多语义的内容
两种模型都是通过将两个对象分开表示，最终计算两个表示的相似度。
不同的是，多语义文档表示方法会考虑不同粒度的表示。

## 直接建模匹配模型的方法
这个方法主要是关注文本表示（局部化或者全局化）为核心的思路，直接建模匹配模式的深度歇息模型，旨在直接捕获到匹配的特征。
实验表明，这种方法在相对复杂的问题上表现更为优秀。
### 主题深度匹配模型
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fqzo9zb4t9j30rj0dggpw.jpg)

### CNN深度匹配模型（ARC-II）
首先是吧句子表示成单词的向量序列，然后使用滑动窗口方法作为基本单元进行卷积操作，得到一个三维的张量，作为两个句子相互作用的初步表示。
随后的卷积对这个三维张量进行卷积+池化的过程，得到一个描述两个句子整体的向量，然后输出到多层感知器中，输出相似结果。
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fqzof8y0aej30xu0csabx.jpg)

### MatchPyramid
ARC-II模型层次化的过程很模糊，MP模型重新定义了两个文本交互的方式——匹配矩阵。然后根据这个**匹配矩阵进行二维的卷积提取匹配空间的模式**，最后通过全连接层的网络得到两个句子之间的相似度。
MatchPymaid核心思想是层次化构建匹配过程。首先定义的匹配矩阵是根据最细粒度的词向量之间的余弦相似度定义的，然后句子之间两两词之间都会计算相似度，根据此在句子空间位置刚好可以构建一个二维的矩阵。
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fr08v07wiqj30q20fegpr.jpg)

之后，把匹配问题看成是这个二维匹配矩阵上的图像识别问题。在卷积层可以得到n-gram的匹配特征。最终得到非常好的效果。
![](https://ws2.sinaimg.cn/large/006tKfTcgy1fr08wmcrv1j30f20o4t9o.jpg)

### Match-SRNN
在得到匹配矩阵之后，Match-RNN发现使用二维的RNN来建模特征空间的模式更为合理。
2D的GRU网络可以模拟最长公共子串的计算过程。

利用之前提到的张量神经网络，捕获到两短文本间的基础交互信息，每个单词可以表示成分布式向量，每个单词之间的交互信息，表示成一个向量形式。
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fr091briskj30hx09sdfy.jpg)

