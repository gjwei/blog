---
title: deep learning 第四章：数值计算
date: 2018-05-08 20:50:58
tags: deeplearning
---
# 数值计算
## 上溢出和下溢出
典型的例子：softmax
如果发生上溢出，会具有毁灭性的，所以，在进行运算的时候，会减去向量中的最大值。

```python
def softmax(a):
    a_max = np.max(a)
    return np.exp(a - a_max) / np.sum(np.exp(a - a_max))
```
<!-- more -->

## 病态条件
条件数是指：函数相对于输入的微小变化而发生变化的快慢程度

病态条件是：输入被轻微的扰动，导致输出的结果发生巨大的变化。

## 基于梯度的优化方法
梯度下降方法。
$f^{'}(x)=0$的点称之为临界点。包括了极小值，极大值或者鞍点

### Jacobian和Hessian矩阵
Jacobian矩阵包含了所有的的偏导数的矩阵。
![](https://ws4.sinaimg.cn/large/006tKfTcgy1fr48pfzla7j30cw0a1gli.jpg)

我们对二阶的导数也很感兴趣，二阶导数提供了导数如何进行变化的信息。是对**曲率的衡量。**

Hessian矩阵就是将所有的二阶导数合并成一个矩阵。可以表示为：
![](https://ws1.sinaimg.cn/large/006tKfTcgy1fr48q3mdggj30l20k5t8v.jpg)

海塞矩阵的作用：可以用来判断临界点是极大点，极小点还是鞍点
对海塞矩阵求解特征值，如果是正定的，则该临界点是全局极小点
如果是负定的，则是全局最大点。
如果是既有正，又有负，则是鞍点。


我们可以使用海塞矩阵的**条件数**衡量二阶导数的变化。如果Hessian条件数很差，那么梯度下降法表现同样很差，因为一个方向的梯度增加的很快，另外一个增加很慢，在进行梯度下降不知道导数的这种变化，所以不知道应该优先探索梯度为负的方向。

病态条件使得学习步长很难选择，步长要足够小，防止在正曲率很大的方向冲出去。但是如果太小，在其他较小曲率方向上又会学习不明显。

解决方法：
1. BatchNormalization，强制数据满足正态分布
2. 自适应学习方法（Adam等）

### Hessian矩阵和牛顿法
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fr4931n9hmj30h009l3ym.jpg)

一般认为牛顿法可以利用曲率的信息，比梯度下降更容易收敛。



## 约束优化问题
参考SVM，主要的方式将使用拉格朗日函数，将约束的问题转为无约束的问题，然后根据KKT条件，将问题转为对偶形式，进行求解。