---
title: 正则化方法
date: 2018-05-03 22:05:03
tags: machine learning
---
# 正则化方法
正则化是对学习算法进行修改，目的是为了减少泛化误差而不是训练误差。利用偏差的增加换取方差的减少。
## 参数的范数惩罚

### L2参数正则化 
经过求解梯度后发现，L2正则每次更新权值，都是对权值乘以一个1-a的系数，所以，也叫做权重衰减。 
所以，L2正则会得到很多很小的权值。
### L1参数正则化 
求解梯度后，可以发现，L1正则每次更新权值，都是对权值增加或者减少固定值a，不再是线性的缩小。这样的结果是有很多不重要特征的权值会直接所见到0. 产生稀疏解。
作为约束的范数惩罚

## 通过一些显示的约束对模型进行正则化。 
比如在树模型中，我们会对每棵树的节点数，深度等进行约束显示。
数据集增强

通过增加数据集，减少噪声数据的影响，从而可以提高模型的泛化能力。
### 噪声鲁棒性

1. 对数据集通过注入噪声的方法，这个可以作为一种数据集增强的方法
### 提前终止

DL这本书中说的是提前终止的效果等价于L2正则化。 
可以将优化的参数空间限制在初始参数值的小领域中，不让他发生太多变化。
### Dropout

提供一种廉价的近似Bagging的集成方法来防止出现过拟合。
### 对抗训练
