---
title: 文本分类中的特征选择和权重计算研究-读博士论文笔记
date: 2018-05-10 19:34:41
tags: NLP
---
# 第一章 引言

## 研究现状

### 文本分类的步骤
1. 建立数据集和预处理
* 收集文本，标注类别，去除非文本内容、编码转换和处理乱码
* 保留词干（steamming）或者回复原型（lemmatize）处理stopwords
* 切分训练集和测试集
<!-- more -->
2. 文本向量化
* 将文本转化为向量的过程
* 文本标引
    * 特征单元：如在BOW中，每个词就是一个特征，对应特征空间中一个维度
    * 权重计算
* 降维
    * 特征选择
    * 特征抽取
        * 将多个特定语法关系的词合并成一个符合特征
        * 通过聚类方法，将相近的特征合并
        * 矩阵分解的方法

3. 学习分类器
4. 测试和评价

### 特征单元
英文中，常用的特征单元有词（word）、词串（word n-gram)和词组（phrase）
目前表明，词是文本分类中表现较好的特征

中文中，常见的特征单元有词，字，子串（character n-grams)及其组合。

实验表明，中文中，单字的语义质量不好，性能较差，可以作为其他特征单元的补充。在信息检索中，
bi-grams的性能最优，略好于词。在文本分类中，词特征和子串特征都具有较好的分类性能。

### 特征选择
* 不相关特征会使分类器对训练集过拟合，从而降低文本分类性能
* 相关但是冗余的特征也会影响性能
* 计算代价的考虑

#### 方法
1. 局部特征选择
2. 全局特征选择：在整个类别集上进行特征选择，得到的特征自己对各个类别是一样的。

* 文本频度（document frequency，df)
训练集中初选特征t_i的文本数；

* 信息增益（information gain，IG）：属于信息论概念，表示特征在文本中出现提供的信息量大小
* $X^2$检验量
目前来说表现最好的指标之一。

后面就是介绍分类模型和数据集，忽略。

# 第二章 中文文本的特征单元
## 词特征和二字串特征
中文文本中没有类似于英文中的空格之类的显示表示词边界的标识，所以需要继续自动分词。

中文文本处理中，词并不是必须的特征单元，字符串类型（characters n-grams)也是高效常用的特征单元，尤其是二字串（bigrams).

子串切分不同于词切分的一个显著区别：**词在文本中是互不重叠的，而字串是重叠的**

如：`我爱天安门` 
词切分：`我/爱/天安门/`
二字串切分：`我爱/爱天/天安/安门/`

所以，按照二字串切分后的特征数量要比词特征数量多很多。

![](https://raw.githubusercontent.com/gjwei/images/master/20180511000702.png)

